Warning: Permanently added '10.42.9.12' (ECDSA) to the list of known hosts.
[2021-11-28 16:33:23,380] [INFO] [runner.py:291:main] Using IP address of 10.42.9.12 for node root@10.42.9.12
[2021-11-28 16:33:23,381] [INFO] [multinode_runner.py:51:get_cmd] Running on the following workers: root@10.42.9.12,root@10.42.93.14,root@10.42.84.22,root@10.42.11.14
[2021-11-28 16:33:23,381] [INFO] [runner.py:360:main] cmd = pdsh -f 1024 -w root@10.42.9.12,root@10.42.93.14,root@10.42.84.22,root@10.42.11.14 export NCCL_IB_DISABLE=0; export NCCL_DEBUG=info; export NCCL_NET_GDR_LEVEL=2; export PYTHONPATH=/dataset/fd5061f6/liuxiao/BlockLM-ssm;  cd /dataset/fd5061f6/liuxiao/BlockLM-ssm; /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJyb290QDEwLjQyLjkuMTIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJyb290QDEwLjQyLjkzLjE0IjogWzAsIDEsIDIsIDMsIDQsIDUsIDYsIDddLCAicm9vdEAxMC40Mi44NC4yMiI6IFswLCAxLCAyLCAzLCA0LCA1LCA2LCA3XSwgInJvb3RAMTAuNDIuMTEuMTQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --node_rank=%n --master_addr=10.42.9.12 --master_port=38350 pretrain_glm.py --block-lm --task-mask --bert-prob '0.5' --gap-sentence-prob '0.3' --avg-block-length '3' --gpt-min-ratio '0.25' --experiment-name 'blocklm-220M-ssm' --model-parallel-size '1' --num-layers '14' --hidden-size '1024' --num-attention-heads '16' --seq-length '512' --max-sequence-length '513' --save '/dataset/fd5061f6/english_data/checkpoints' --train-iters '200000' --resume-dataloader --train-data 'wikipedia_ssm' --tokenizer-type 'GPT2BPETokenizer' --tokenizer-model-type 'gpt2' --split '949,50,1' --distributed-backend 'nccl' --lr-decay-style 'cosine' --lr-decay-iters '160000' --lr-decay-ratio '0.05' --warmup '.05' --checkpoint-activations --fp16 --deepspeed --deepspeed_config '/dataset/fd5061f6/liuxiao/BlockLM-ssm/config/config_block_220M.json'
10.42.9.12: Warning: Permanently added '10.42.9.12' (ECDSA) to the list of known hosts.
10.42.84.22: Warning: Permanently added '10.42.84.22' (ECDSA) to the list of known hosts.
10.42.11.14: Warning: Permanently added '10.42.11.14' (ECDSA) to the list of known hosts.
10.42.93.14: Warning: Permanently added '10.42.93.14' (ECDSA) to the list of known hosts.
10.42.9.12: [2021-11-28 16:33:24,177] [INFO] [launch.py:73:main] 0 NCCL_NET_GDR_LEVEL 2
10.42.9.12: [2021-11-28 16:33:24,177] [INFO] [launch.py:73:main] 0 NCCL_DEBUG info
10.42.9.12: [2021-11-28 16:33:24,178] [INFO] [launch.py:73:main] 0 NCCL_IB_DISABLE 0
10.42.9.12: [2021-11-28 16:33:24,178] [INFO] [launch.py:80:main] WORLD INFO DICT: {'root@10.42.9.12': [0, 1, 2, 3, 4, 5, 6, 7], 'root@10.42.93.14': [0, 1, 2, 3, 4, 5, 6, 7], 'root@10.42.84.22': [0, 1, 2, 3, 4, 5, 6, 7], 'root@10.42.11.14': [0, 1, 2, 3, 4, 5, 6, 7]}
10.42.9.12: [2021-11-28 16:33:24,178] [INFO] [launch.py:86:main] nnodes=4, num_local_procs=8, node_rank=0
10.42.9.12: [2021-11-28 16:33:24,178] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'root@10.42.9.12': [0, 1, 2, 3, 4, 5, 6, 7], 'root@10.42.93.14': [8, 9, 10, 11, 12, 13, 14, 15], 'root@10.42.84.22': [16, 17, 18, 19, 20, 21, 22, 23], 'root@10.42.11.14': [24, 25, 26, 27, 28, 29, 30, 31]})
10.42.9.12: [2021-11-28 16:33:24,178] [INFO] [launch.py:102:main] dist_world_size=32
10.42.9.12: [2021-11-28 16:33:24,178] [INFO] [launch.py:104:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
10.42.84.22: [2021-11-28 16:33:24,193] [INFO] [launch.py:73:main] 2 NCCL_NET_GDR_LEVEL 2
10.42.84.22: [2021-11-28 16:33:24,193] [INFO] [launch.py:73:main] 2 NCCL_DEBUG info
10.42.84.22: [2021-11-28 16:33:24,193] [INFO] [launch.py:73:main] 2 NCCL_IB_DISABLE 0
10.42.84.22: [2021-11-28 16:33:24,193] [INFO] [launch.py:80:main] WORLD INFO DICT: {'root@10.42.9.12': [0, 1, 2, 3, 4, 5, 6, 7], 'root@10.42.93.14': [0, 1, 2, 3, 4, 5, 6, 7], 'root@10.42.84.22': [0, 1, 2, 3, 4, 5, 6, 7], 'root@10.42.11.14': [0, 1, 2, 3, 4, 5, 6, 7]}
10.42.84.22: [2021-11-28 16:33:24,193] [INFO] [launch.py:86:main] nnodes=4, num_local_procs=8, node_rank=2
10.42.84.22: [2021-11-28 16:33:24,193] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'root@10.42.9.12': [0, 1, 2, 3, 4, 5, 6, 7], 'root@10.42.93.14': [8, 9, 10, 11, 12, 13, 14, 15], 'root@10.42.84.22': [16, 17, 18, 19, 20, 21, 22, 23], 'root@10.42.11.14': [24, 25, 26, 27, 28, 29, 30, 31]})
10.42.84.22: [2021-11-28 16:33:24,193] [INFO] [launch.py:102:main] dist_world_size=32
10.42.84.22: [2021-11-28 16:33:24,193] [INFO] [launch.py:104:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
10.42.11.14: [2021-11-28 16:33:24,217] [INFO] [launch.py:73:main] 3 NCCL_NET_GDR_LEVEL 2
10.42.11.14: [2021-11-28 16:33:24,217] [INFO] [launch.py:73:main] 3 NCCL_DEBUG info
10.42.11.14: [2021-11-28 16:33:24,217] [INFO] [launch.py:73:main] 3 NCCL_IB_DISABLE 0
10.42.11.14: [2021-11-28 16:33:24,217] [INFO] [launch.py:80:main] WORLD INFO DICT: {'root@10.42.9.12': [0, 1, 2, 3, 4, 5, 6, 7], 'root@10.42.93.14': [0, 1, 2, 3, 4, 5, 6, 7], 'root@10.42.84.22': [0, 1, 2, 3, 4, 5, 6, 7], 'root@10.42.11.14': [0, 1, 2, 3, 4, 5, 6, 7]}
10.42.11.14: [2021-11-28 16:33:24,217] [INFO] [launch.py:86:main] nnodes=4, num_local_procs=8, node_rank=3
10.42.11.14: [2021-11-28 16:33:24,217] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'root@10.42.9.12': [0, 1, 2, 3, 4, 5, 6, 7], 'root@10.42.93.14': [8, 9, 10, 11, 12, 13, 14, 15], 'root@10.42.84.22': [16, 17, 18, 19, 20, 21, 22, 23], 'root@10.42.11.14': [24, 25, 26, 27, 28, 29, 30, 31]})
10.42.11.14: [2021-11-28 16:33:24,217] [INFO] [launch.py:102:main] dist_world_size=32
10.42.11.14: [2021-11-28 16:33:24,217] [INFO] [launch.py:104:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
10.42.93.14: [2021-11-28 16:33:24,228] [INFO] [launch.py:73:main] 1 NCCL_NET_GDR_LEVEL 2
10.42.93.14: [2021-11-28 16:33:24,228] [INFO] [launch.py:73:main] 1 NCCL_DEBUG info
10.42.93.14: [2021-11-28 16:33:24,228] [INFO] [launch.py:73:main] 1 NCCL_IB_DISABLE 0
10.42.93.14: [2021-11-28 16:33:24,228] [INFO] [launch.py:80:main] WORLD INFO DICT: {'root@10.42.9.12': [0, 1, 2, 3, 4, 5, 6, 7], 'root@10.42.93.14': [0, 1, 2, 3, 4, 5, 6, 7], 'root@10.42.84.22': [0, 1, 2, 3, 4, 5, 6, 7], 'root@10.42.11.14': [0, 1, 2, 3, 4, 5, 6, 7]}
10.42.93.14: [2021-11-28 16:33:24,228] [INFO] [launch.py:86:main] nnodes=4, num_local_procs=8, node_rank=1
10.42.93.14: [2021-11-28 16:33:24,228] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'root@10.42.9.12': [0, 1, 2, 3, 4, 5, 6, 7], 'root@10.42.93.14': [8, 9, 10, 11, 12, 13, 14, 15], 'root@10.42.84.22': [16, 17, 18, 19, 20, 21, 22, 23], 'root@10.42.11.14': [24, 25, 26, 27, 28, 29, 30, 31]})
10.42.93.14: [2021-11-28 16:33:24,228] [INFO] [launch.py:102:main] dist_world_size=32
10.42.93.14: [2021-11-28 16:33:24,228] [INFO] [launch.py:104:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
10.42.9.12: using world size: 32 and model-parallel size: 1 
10.42.9.12: > initializing model parallel with size 1
10.42.9.12: [2021-11-28 16:33:29,663] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.93.14: [2021-11-28 16:33:29,668] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.84.22: [2021-11-28 16:33:29,662] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.11.14: [2021-11-28 16:33:29,661] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.11.14: [2021-11-28 16:33:29,661] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.9.12: [2021-11-28 16:33:29,663] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.11.14: [2021-11-28 16:33:29,662] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.93.14: [2021-11-28 16:33:29,668] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.93.14: [2021-11-28 16:33:29,668] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.93.14: [2021-11-28 16:33:29,668] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.93.14: [2021-11-28 16:33:29,668] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.11.14: [2021-11-28 16:33:29,662] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.11.14: [2021-11-28 16:33:29,662] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.93.14: [2021-11-28 16:33:29,668] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.11.14: [2021-11-28 16:33:29,662] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.11.14: [2021-11-28 16:33:29,662] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.84.22: [2021-11-28 16:33:29,662] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.93.14: [2021-11-28 16:33:29,669] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.11.14: [2021-11-28 16:33:29,662] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.84.22: [2021-11-28 16:33:29,668] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.84.22: [2021-11-28 16:33:29,668] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.84.22: [2021-11-28 16:33:29,668] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.84.22: [2021-11-28 16:33:29,668] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.9.12: [2021-11-28 16:33:29,670] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.9.12: [2021-11-28 16:33:29,670] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.9.12: [2021-11-28 16:33:29,670] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.9.12: [2021-11-28 16:33:29,670] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.9.12: [2021-11-28 16:33:29,670] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.93.14: [2021-11-28 16:33:29,675] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.84.22: [2021-11-28 16:33:29,668] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.84.22: [2021-11-28 16:33:29,668] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.9.12: [2021-11-28 16:33:29,670] [WARNING] [config.py:79:_sanity_check] DeepSpeedConfig: cpu_offload is deprecated. Please use offload_optimizer.
10.42.9.12: [2021-11-28 16:33:29,670] [INFO] [checkpointing.py:734:_configure_using_config_file] {'partition_activations': False, 'contiguous_memory_optimization': False, 'cpu_checkpointing': False, 'number_checkpoints': None, 'synchronize_checkpoint_boundary': False, 'profile': False}
10.42.9.12: [2021-11-28 16:33:29,671] [INFO] [checkpointing.py:223:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
10.42.9.12: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.93.14: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.9.12: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.84.22: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.84.22: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.93.14: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.11.14: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.84.22: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.11.14: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.11.14: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.11.14: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.11.14: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.11.14: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.11.14: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.84.22: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)][CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.84.22: 
10.42.84.22: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.93.14: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.93.14: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.9.12: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.11.14: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.9.12: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.9.12: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.9.12: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.9.12: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.9.12: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.84.22: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)][CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.84.22: 
10.42.93.14: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.93.14: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.93.14: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.93.14: [CommandToken(name='pad', token='<|endoftext|>', Id=50256), CommandToken(name='eos', token='<|endoftext|>', Id=50256), CommandToken(name='sop', token='<|startofpiece|>', Id=50257), CommandToken(name='eop', token='<|endofpiece|>', Id=50258), CommandToken(name='ENC', token='[CLS]', Id=50259), CommandToken(name='MASK', token='[MASK]', Id=50260), CommandToken(name='sep', token='[SEP]', Id=50261), CommandToken(name='unk', token='[UNK]', Id=50262), CommandToken(name='gMASK', token='[gMASK]', Id=50263), CommandToken(name='sMASK', token='[sMASK]', Id=50264)]
10.42.9.12: > padded vocab (size: 50265) with 39 dummy tokens (new size: 50304)
10.42.9.12: prepare tokenizer done
10.42.9.12: configuring data
10.42.9.12: Creating lazy loader for dataset wikipedia_ssm
10.42.84.22: Traceback (most recent call last):
10.42.84.22:   File "pretrain_glm.py", line 543, in <module>
10.42.11.14: Traceback (most recent call last):
10.42.11.14:   File "pretrain_glm.py", line 543, in <module>
10.42.11.14: Traceback (most recent call last):
10.42.11.14:   File "pretrain_glm.py", line 543, in <module>
10.42.84.22: Traceback (most recent call last):
10.42.84.22:   File "pretrain_glm.py", line 543, in <module>
10.42.11.14: Traceback (most recent call last):
10.42.11.14:   File "pretrain_glm.py", line 543, in <module>
10.42.11.14: Traceback (most recent call last):
10.42.11.14:   File "pretrain_glm.py", line 543, in <module>
10.42.84.22: Traceback (most recent call last):
10.42.84.22:   File "pretrain_glm.py", line 543, in <module>
10.42.11.14:     main()
10.42.11.14:   File "pretrain_glm.py", line 451, in main
10.42.84.22:     main()    
10.42.84.22: main()
10.42.84.22:   File "pretrain_glm.py", line 451, in main
10.42.11.14:     main()
10.42.11.14:   File "pretrain_glm.py", line 451, in main
10.42.11.14:     main()
10.42.11.14:   File "pretrain_glm.py", line 451, in main
10.42.84.22:   File "pretrain_glm.py", line 451, in main
10.42.84.22:     main()
10.42.84.22:   File "pretrain_glm.py", line 451, in main
10.42.11.14:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.11.14:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.11.14:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.11.14:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.11.14:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.11.14:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.11.14:     main()
10.42.11.14:   File "pretrain_glm.py", line 451, in main
10.42.84.22:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.84.22:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.84.22:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.84.22:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.84.22:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.84.22:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.11.14:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.11.14:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.84.22:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.84.22:       File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.84.22:     train_data, val_data, test_data = data_config.apply(args, tokenizer)train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.84.22: 
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.11.14:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.11.14:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.11.14:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.11.14:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.11.14: Traceback (most recent call last):
10.42.11.14:   File "pretrain_glm.py", line 543, in <module>
10.42.84.22:     return make_loaders(args, tokenizer)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.11.14:         return make_loaders(args, tokenizer)return make_loaders(args, tokenizer)
10.42.11.14: 
10.42.11.14:       File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.84.22:     return make_loaders(args, tokenizer)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.11.14: return make_loaders(args, tokenizer)  File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.11.14: 
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.11.14:     return make_loaders(args, tokenizer)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.84.22:     return make_loaders(args, tokenizer)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.84.22:     train = data_utils.make_dataset(**data_set_args)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.84.22:     train = data_utils.make_dataset(**data_set_args)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.11.14:     train = data_utils.make_dataset(**data_set_args)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.11.14:     train = data_utils.make_dataset(**data_set_args)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.11.14:     train = data_utils.make_dataset(**data_set_args)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.11.14:     train = data_utils.make_dataset(**data_set_args)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.84.22:     train = data_utils.make_dataset(**data_set_args)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.93.14: Traceback (most recent call last):
10.42.93.14:   File "pretrain_glm.py", line 543, in <module>
10.42.84.22:         _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,_datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.84.22: 
10.42.84.22:       File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.11.14:         _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,_datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.11.14: 
10.42.11.14:       File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.84.22: _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.11.14: _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.11.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.11.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.11.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.11.14:     main()
10.42.11.14:   File "pretrain_glm.py", line 451, in main
10.42.93.14:     main()
10.42.93.14:   File "pretrain_glm.py", line 451, in main
10.42.84.22:         _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,_datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.84.22: 
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.84.22:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.11.14:         prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,_datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.11.14: 
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.11.14:             prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,_datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.84.22:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.84.22:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.11.14: 
10.42.11.14: 
10.42.84.22:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.11.14:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.11.14: Traceback (most recent call last):
10.42.11.14:   File "pretrain_glm.py", line 543, in <module>
10.42.84.22: Traceback (most recent call last):
10.42.84.22:   File "pretrain_glm.py", line 543, in <module>
10.42.84.22:         self.lens = pkl.load(open(lenpath, 'rb'))self.lens = pkl.load(open(lenpath, 'rb'))
10.42.84.22: 
10.42.11.14:         self.lens = pkl.load(open(lenpath, 'rb'))self.lens = pkl.load(open(lenpath, 'rb'))
10.42.11.14: 
10.42.84.22: EOFErrorEOFError: Ran out of input
10.42.84.22: : Ran out of input
10.42.11.14: EOFErrorEOFError: : Ran out of inputRan out of input
10.42.11.14: 
10.42.11.14:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.11.14:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.11.14: EOFError: Ran out of input
10.42.93.14: Traceback (most recent call last):
10.42.93.14:   File "pretrain_glm.py", line 543, in <module>
10.42.11.14: EOFError: Ran out of input
10.42.84.22:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.84.22: EOFError: Ran out of input
10.42.84.22: Traceback (most recent call last):
10.42.84.22:   File "pretrain_glm.py", line 543, in <module>
10.42.93.14: Traceback (most recent call last):
10.42.93.14:   File "pretrain_glm.py", line 543, in <module>
10.42.93.14:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.11.14:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.93.14:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.11.14:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.93.14:     main()
10.42.93.14:   File "pretrain_glm.py", line 451, in main
10.42.11.14: Traceback (most recent call last):
10.42.11.14:   File "pretrain_glm.py", line 543, in <module>
10.42.93.14:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.11.14:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.93.14:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.93.14:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.93.14:     main()
10.42.93.14:   File "pretrain_glm.py", line 451, in main
10.42.11.14:     main()
10.42.11.14:   File "pretrain_glm.py", line 451, in main
10.42.93.14:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.84.22:     main()    
10.42.84.22: main()
10.42.84.22:   File "pretrain_glm.py", line 451, in main
10.42.84.22:   File "pretrain_glm.py", line 451, in main
10.42.11.14:     main()
10.42.11.14:   File "pretrain_glm.py", line 451, in main
10.42.11.14:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.11.14:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.93.14:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.93.14:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.93.14:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.11.14:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.84.22:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.84.22:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.84.22:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.84.22:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.11.14:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.11.14:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.11.14:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.84.22:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.84.22:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.11.14: Traceback (most recent call last):
10.42.11.14:   File "pretrain_glm.py", line 543, in <module>
10.42.11.14:     main()
10.42.11.14:   File "pretrain_glm.py", line 451, in main
10.42.11.14:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.11.14:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.11.14:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.11.14:     return make_loaders(args, tokenizer)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.93.14:         return make_loaders(args, tokenizer)return make_loaders(args, tokenizer)
10.42.93.14: 
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.84.22:     return make_loaders(args, tokenizer)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.11.14:     return make_loaders(args, tokenizer)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.84.22:     return make_loaders(args, tokenizer)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.11.14:     return make_loaders(args, tokenizer)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.11.14:     train = data_utils.make_dataset(**data_set_args)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.93.14:     train = data_utils.make_dataset(**data_set_args)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.93.14:     train = data_utils.make_dataset(**data_set_args)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.11.14:     train = data_utils.make_dataset(**data_set_args)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.84.22:     train = data_utils.make_dataset(**data_set_args)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.11.14:     train = data_utils.make_dataset(**data_set_args)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.84.22:     train = data_utils.make_dataset(**data_set_args)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.11.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.11.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.93.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.11.14:     return make_loaders(args, tokenizer)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.93.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.93.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.11.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.93.14:     return make_loaders(args, tokenizer)    
10.42.84.22:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.11.14:       File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.93.14: _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.11.14: _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.11.14:     train = data_utils.make_dataset(**data_set_args)
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.11.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.93.14:     train = data_utils.make_dataset(**data_set_args)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.84.22:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.11.14:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.11.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.93.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.11.14:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.11.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.93.14:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.84.22:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.84.22:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,  File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.11.14:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.84.22: 
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.84.22:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.84.22:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.93.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.11.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.93.14:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.93.14:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.11.14:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.11.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.9.12: Traceback (most recent call last):
10.42.9.12:   File "pretrain_glm.py", line 543, in <module>
10.42.11.14:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.11.14: EOFError: Ran out of input
10.42.11.14:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.11.14: EOFError: Ran out of input
10.42.93.14:         self.lens = pkl.load(open(lenpath, 'rb'))self.lens = pkl.load(open(lenpath, 'rb'))
10.42.93.14: 
10.42.93.14: EOFErrorEOFError: : Ran out of inputRan out of input
10.42.93.14:     
10.42.93.14: self.lens = pkl.load(open(lenpath, 'rb'))
10.42.84.22:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.84.22: EOFError: Ran out of input
10.42.11.14:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.84.22:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.84.22: EOFError: Ran out of input
10.42.93.14: EOFError: Ran out of input
10.42.11.14: EOFError: Ran out of input
10.42.11.14:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.11.14: EOFError: Ran out of input
10.42.9.12: Traceback (most recent call last):
10.42.9.12:   File "pretrain_glm.py", line 543, in <module>
10.42.9.12: Traceback (most recent call last):
10.42.9.12:   File "pretrain_glm.py", line 543, in <module>
10.42.9.12: Traceback (most recent call last):
10.42.9.12:   File "pretrain_glm.py", line 543, in <module>
10.42.9.12: Traceback (most recent call last):
10.42.9.12:   File "pretrain_glm.py", line 543, in <module>
10.42.9.12:     main()    
10.42.9.12: main()  File "pretrain_glm.py", line 451, in main
10.42.9.12: 
10.42.9.12:   File "pretrain_glm.py", line 451, in main
10.42.9.12:     main()
10.42.9.12:   File "pretrain_glm.py", line 451, in main
10.42.9.12:     main()
10.42.9.12:       File "pretrain_glm.py", line 451, in main
10.42.9.12: main()
10.42.9.12:   File "pretrain_glm.py", line 451, in main
10.42.9.12: Traceback (most recent call last):
10.42.9.12:   File "pretrain_glm.py", line 543, in <module>
10.42.93.14: Traceback (most recent call last):
10.42.93.14:   File "pretrain_glm.py", line 543, in <module>
10.42.93.14: Traceback (most recent call last):
10.42.93.14:   File "pretrain_glm.py", line 543, in <module>
10.42.9.12: Traceback (most recent call last):
10.42.9.12:   File "pretrain_glm.py", line 543, in <module>
10.42.84.22: Traceback (most recent call last):
10.42.84.22:   File "pretrain_glm.py", line 543, in <module>
10.42.9.12:         train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.9.12: 
10.42.9.12:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.9.12:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.9.12:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.9.12:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.9.12:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.9.12:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.9.12:     main()
10.42.9.12:   File "pretrain_glm.py", line 451, in main
10.42.93.14:     main()
10.42.93.14:   File "pretrain_glm.py", line 451, in main
10.42.84.22:     main()
10.42.84.22:   File "pretrain_glm.py", line 451, in main
10.42.9.12:             main()train_data, val_data, test_data = data_config.apply(args, tokenizer)train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.9.12: 
10.42.9.12: 
10.42.9.12:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.9.12:   File "pretrain_glm.py", line 451, in main
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.9.12:             train_data, val_data, test_data = data_config.apply(args, tokenizer)train_data, val_data, test_data = data_config.apply(args, tokenizer)train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.9.12: 
10.42.9.12: 
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.93.14:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.9.12:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.9.12:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.9.12:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.9.12:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.9.12:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.84.22:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.93.14:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.84.22:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.9.12:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.84.22:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.93.14:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.9.12:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.93.14:     main()
10.42.93.14:   File "pretrain_glm.py", line 451, in main
10.42.9.12:     return make_loaders(args, tokenizer)
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.84.22:     return make_loaders(args, tokenizer)
10.42.9.12:     return make_loaders(args, tokenizer)
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.9.12:         return make_loaders(args, tokenizer)return make_loaders(args, tokenizer)
10.42.9.12: 
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.9.12:     return make_loaders(args, tokenizer)
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.93.14:     return make_loaders(args, tokenizer)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.9.12:     return make_loaders(args, tokenizer)
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.93.14:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.93.14:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.9.12:     train = data_utils.make_dataset(**data_set_args)
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.84.22:     train = data_utils.make_dataset(**data_set_args)
10.42.9.12:         train = data_utils.make_dataset(**data_set_args)train = data_utils.make_dataset(**data_set_args)
10.42.9.12: 
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.9.12:     train = data_utils.make_dataset(**data_set_args)
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.9.12:     train = data_utils.make_dataset(**data_set_args)
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.93.14:     train = data_utils.make_dataset(**data_set_args)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.9.12:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.9.12:       File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.9.12: _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,    
10.42.84.22:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.9.12: _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,    
10.42.9.12: _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,  File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.9.12: 
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.93.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.9.12:         _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,train = data_utils.make_dataset(**data_set_args)
10.42.9.12: 
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.9.12:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.9.12:       File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.9.12: _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,    
10.42.9.12: _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.84.22:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.9.12:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.93.14:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.93.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.93.14:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.84.22:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.9.12:         prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,_datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.9.12: 
10.42.9.12:       File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.9.12: prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,  File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.9.12: 
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.9.12:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.9.12:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.9.12:       File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.9.12: _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.9.12:     return make_loaders(args, tokenizer)
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.93.14:     return make_loaders(args, tokenizer)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.9.12:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.93.14:     train = data_utils.make_dataset(**data_set_args)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.9.12:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.9.12:     train = data_utils.make_dataset(**data_set_args)
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.9.12:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.9.12:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.93.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.93.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.9.12:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.93.14:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.9.12:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.9.12:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.84.22: Traceback (most recent call last):
10.42.84.22:   File "pretrain_glm.py", line 543, in <module>
10.42.93.14: Traceback (most recent call last):
10.42.93.14:   File "pretrain_glm.py", line 543, in <module>
10.42.93.14:     main()
10.42.93.14:   File "pretrain_glm.py", line 451, in main
10.42.84.22:     main()
10.42.84.22:   File "pretrain_glm.py", line 451, in main
10.42.93.14:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.84.22:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.93.14:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.84.22:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.84.22:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.93.14:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.84.22:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.9.12:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.9.12: EOFError: Ran out of input
10.42.9.12:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.9.12:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.9.12:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.9.12: EOFErrorEOFError: : Ran out of inputRan out of inputEOFError
10.42.9.12: 
10.42.9.12: : Ran out of input
10.42.84.22: EOFError: Ran out of input
10.42.93.14:         self.lens = pkl.load(open(lenpath, 'rb'))self.lens = pkl.load(open(lenpath, 'rb'))
10.42.93.14: 
10.42.93.14: EOFErrorEOFError: : Ran out of inputRan out of input
10.42.93.14: 
10.42.9.12:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.9.12: EOFError: Ran out of input
10.42.9.12:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.9.12: EOFError: Ran out of input
10.42.9.12:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.9.12: EOFError: Ran out of input
10.42.84.22:     return make_loaders(args, tokenizer)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.93.14:     return make_loaders(args, tokenizer)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.84.22:     train = data_utils.make_dataset(**data_set_args)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.93.14:     train = data_utils.make_dataset(**data_set_args)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.84.22:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.93.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.84.22:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.93.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.84.22:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.93.14:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.84.22:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.84.22: EOFError: Ran out of input
10.42.93.14: Traceback (most recent call last):
10.42.93.14:   File "pretrain_glm.py", line 543, in <module>
10.42.93.14:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.93.14: EOFError: Ran out of input
10.42.93.14:     main()
10.42.93.14:   File "pretrain_glm.py", line 451, in main
10.42.93.14:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.93.14:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.93.14:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.93.14: Traceback (most recent call last):
10.42.93.14:   File "pretrain_glm.py", line 543, in <module>
10.42.93.14:     main()
10.42.93.14:   File "pretrain_glm.py", line 451, in main
10.42.93.14:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.93.14:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.93.14:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.93.14:     return make_loaders(args, tokenizer)    
10.42.93.14: return make_loaders(args, tokenizer)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.93.14:     train = data_utils.make_dataset(**data_set_args)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.93.14:     train = data_utils.make_dataset(**data_set_args)
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.93.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.93.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.93.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.93.14:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.93.14:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.93.14:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.93.14:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.93.14:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.93.14: EOFError: Ran out of input
10.42.93.14:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.93.14: EOFError: Ran out of input
10.42.84.22: Traceback (most recent call last):
10.42.84.22:   File "pretrain_glm.py", line 543, in <module>
10.42.84.22:     main()
10.42.84.22:   File "pretrain_glm.py", line 451, in main
10.42.84.22:     train_data, val_data, test_data, = get_train_val_test_data(args, tokenizer)
10.42.84.22:   File "pretrain_glm.py", line 409, in get_train_val_test_data
10.42.84.22:     train_data, val_data, test_data = data_config.apply(args, tokenizer)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 119, in apply
10.42.84.22:     return make_loaders(args, tokenizer)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/configure_data.py", line 236, in make_loaders
10.42.84.22:     train = data_utils.make_dataset(**data_set_args)
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in make_dataset
10.42.84.22:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 163, in <listcomp>
10.42.84.22:     _datasets = [get_dataset(p, tokenizer=tokenizer, pre_tokenize=pre_tokenize, no_lazy_loader=no_lazy_loader,
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/__init__.py", line 98, in get_dataset
10.42.84.22:     prompts = LazyLoader(lazy_path, data_type='prompt', map_fn=map_fn, mem_map=True,
10.42.84.22:   File "/dataset/fd5061f6/liuxiao/BlockLM-ssm/data_utils/lazy_loader.py", line 190, in __init__
10.42.84.22:     self.lens = pkl.load(open(lenpath, 'rb'))
10.42.84.22: EOFError: Ran out of input
10.42.9.12: Killing subprocess 2683965
10.42.9.12: Killing subprocess 2683966
10.42.9.12: Killing subprocess 2683967
10.42.9.12: Killing subprocess 2683968
10.42.9.12: Killing subprocess 2683969
10.42.9.12: Killing subprocess 2683970
10.42.9.12: Killing subprocess 2683971
10.42.9.12: Killing subprocess 2683972
10.42.9.12: Traceback (most recent call last):
10.42.9.12:   File "/opt/conda/lib/python3.8/runpy.py", line 194, in _run_module_as_main
10.42.9.12:     return _run_code(code, main_globals, None,
10.42.9.12:   File "/opt/conda/lib/python3.8/runpy.py", line 87, in _run_code
10.42.9.12:     exec(code, run_globals)
10.42.9.12:   File "/opt/conda/lib/python3.8/site-packages/deepspeed/launcher/launch.py", line 171, in <module>
10.42.9.12:     main()
10.42.9.12:   File "/opt/conda/lib/python3.8/site-packages/deepspeed/launcher/launch.py", line 161, in main
10.42.9.12:     sigkill_handler(signal.SIGTERM, None)  # not coming back
10.42.9.12:   File "/opt/conda/lib/python3.8/site-packages/deepspeed/launcher/launch.py", line 139, in sigkill_handler
10.42.9.12:     raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
10.42.9.12: subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', 'pretrain_glm.py', '--local_rank=7', '--block-lm', '--task-mask', '--bert-prob', '0.5', '--gap-sentence-prob', '0.3', '--avg-block-length', '3', '--gpt-min-ratio', '0.25', '--experiment-name', 'blocklm-220M-ssm', '--model-parallel-size', '1', '--num-layers', '14', '--hidden-size', '1024', '--num-attention-heads', '16', '--seq-length', '512', '--max-sequence-length', '513', '--save', '/dataset/fd5061f6/english_data/checkpoints', '--train-iters', '200000', '--resume-dataloader', '--train-data', 'wikipedia_ssm', '--tokenizer-type', 'GPT2BPETokenizer', '--tokenizer-model-type', 'gpt2', '--split', '949,50,1', '--distributed-backend', 'nccl', '--lr-decay-style', 'cosine', '--lr-decay-iters', '160000', '--lr-decay-ratio', '0.05', '--warmup', '.05', '--checkpoint-activations', '--fp16', '--deepspeed', '--deepspeed_config', '/dataset/fd5061f6/liuxiao/BlockLM-ssm/config/config_block_220M.json']' returned non-zero exit status 1.
10.42.84.22: Killing subprocess 555300
10.42.84.22: Killing subprocess 555301
10.42.84.22: Killing subprocess 555302
10.42.84.22: Killing subprocess 555303
10.42.84.22: Killing subprocess 555304
10.42.84.22: Killing subprocess 555305
10.42.84.22: Killing subprocess 555306
10.42.84.22: Killing subprocess 555307
10.42.84.22: Traceback (most recent call last):
10.42.84.22:   File "/opt/conda/lib/python3.8/runpy.py", line 194, in _run_module_as_main
10.42.84.22:     return _run_code(code, main_globals, None,
10.42.84.22:   File "/opt/conda/lib/python3.8/runpy.py", line 87, in _run_code
10.42.84.22:     exec(code, run_globals)
10.42.84.22:   File "/opt/conda/lib/python3.8/site-packages/deepspeed/launcher/launch.py", line 171, in <module>
10.42.84.22:     main()
10.42.84.22:   File "/opt/conda/lib/python3.8/site-packages/deepspeed/launcher/launch.py", line 161, in main
10.42.84.22:     sigkill_handler(signal.SIGTERM, None)  # not coming back
10.42.84.22:   File "/opt/conda/lib/python3.8/site-packages/deepspeed/launcher/launch.py", line 139, in sigkill_handler
10.42.84.22:     raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
10.42.84.22: subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', 'pretrain_glm.py', '--local_rank=7', '--block-lm', '--task-mask', '--bert-prob', '0.5', '--gap-sentence-prob', '0.3', '--avg-block-length', '3', '--gpt-min-ratio', '0.25', '--experiment-name', 'blocklm-220M-ssm', '--model-parallel-size', '1', '--num-layers', '14', '--hidden-size', '1024', '--num-attention-heads', '16', '--seq-length', '512', '--max-sequence-length', '513', '--save', '/dataset/fd5061f6/english_data/checkpoints', '--train-iters', '200000', '--resume-dataloader', '--train-data', 'wikipedia_ssm', '--tokenizer-type', 'GPT2BPETokenizer', '--tokenizer-model-type', 'gpt2', '--split', '949,50,1', '--distributed-backend', 'nccl', '--lr-decay-style', 'cosine', '--lr-decay-iters', '160000', '--lr-decay-ratio', '0.05', '--warmup', '.05', '--checkpoint-activations', '--fp16', '--deepspeed', '--deepspeed_config', '/dataset/fd5061f6/liuxiao/BlockLM-ssm/config/config_block_220M.json']' returned non-zero exit status 1.
10.42.11.14: Killing subprocess 758209
10.42.11.14: Killing subprocess 758210
10.42.11.14: Killing subprocess 758211
10.42.11.14: Killing subprocess 758212
10.42.11.14: Killing subprocess 758213
10.42.11.14: Killing subprocess 758214
10.42.11.14: Killing subprocess 758215
10.42.11.14: Killing subprocess 758216
10.42.11.14: Traceback (most recent call last):
10.42.11.14:   File "/opt/conda/lib/python3.8/runpy.py", line 194, in _run_module_as_main
10.42.11.14:     return _run_code(code, main_globals, None,
10.42.11.14:   File "/opt/conda/lib/python3.8/runpy.py", line 87, in _run_code
10.42.11.14:     exec(code, run_globals)
10.42.11.14:   File "/opt/conda/lib/python3.8/site-packages/deepspeed/launcher/launch.py", line 171, in <module>
10.42.11.14:     main()
10.42.11.14:   File "/opt/conda/lib/python3.8/site-packages/deepspeed/launcher/launch.py", line 161, in main
10.42.11.14:     sigkill_handler(signal.SIGTERM, None)  # not coming back
10.42.11.14:   File "/opt/conda/lib/python3.8/site-packages/deepspeed/launcher/launch.py", line 139, in sigkill_handler
10.42.11.14:     raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
10.42.11.14: subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', 'pretrain_glm.py', '--local_rank=7', '--block-lm', '--task-mask', '--bert-prob', '0.5', '--gap-sentence-prob', '0.3', '--avg-block-length', '3', '--gpt-min-ratio', '0.25', '--experiment-name', 'blocklm-220M-ssm', '--model-parallel-size', '1', '--num-layers', '14', '--hidden-size', '1024', '--num-attention-heads', '16', '--seq-length', '512', '--max-sequence-length', '513', '--save', '/dataset/fd5061f6/english_data/checkpoints', '--train-iters', '200000', '--resume-dataloader', '--train-data', 'wikipedia_ssm', '--tokenizer-type', 'GPT2BPETokenizer', '--tokenizer-model-type', 'gpt2', '--split', '949,50,1', '--distributed-backend', 'nccl', '--lr-decay-style', 'cosine', '--lr-decay-iters', '160000', '--lr-decay-ratio', '0.05', '--warmup', '.05', '--checkpoint-activations', '--fp16', '--deepspeed', '--deepspeed_config', '/dataset/fd5061f6/liuxiao/BlockLM-ssm/config/config_block_220M.json']' returned non-zero exit status 1.
10.42.93.14: Killing subprocess 931879
10.42.93.14: Killing subprocess 931880
10.42.93.14: Killing subprocess 931881
10.42.93.14: Killing subprocess 931882
10.42.93.14: Killing subprocess 931883
10.42.93.14: Killing subprocess 931884
10.42.93.14: Killing subprocess 931885
10.42.93.14: Killing subprocess 931886
10.42.93.14: Traceback (most recent call last):
10.42.93.14:   File "/opt/conda/lib/python3.8/runpy.py", line 194, in _run_module_as_main
10.42.93.14:     return _run_code(code, main_globals, None,
10.42.93.14:   File "/opt/conda/lib/python3.8/runpy.py", line 87, in _run_code
10.42.93.14:     exec(code, run_globals)
10.42.93.14:   File "/opt/conda/lib/python3.8/site-packages/deepspeed/launcher/launch.py", line 171, in <module>
10.42.93.14:     main()
10.42.93.14:   File "/opt/conda/lib/python3.8/site-packages/deepspeed/launcher/launch.py", line 161, in main
10.42.93.14:     sigkill_handler(signal.SIGTERM, None)  # not coming back
10.42.93.14:   File "/opt/conda/lib/python3.8/site-packages/deepspeed/launcher/launch.py", line 139, in sigkill_handler
10.42.93.14:     raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
10.42.93.14: subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', 'pretrain_glm.py', '--local_rank=7', '--block-lm', '--task-mask', '--bert-prob', '0.5', '--gap-sentence-prob', '0.3', '--avg-block-length', '3', '--gpt-min-ratio', '0.25', '--experiment-name', 'blocklm-220M-ssm', '--model-parallel-size', '1', '--num-layers', '14', '--hidden-size', '1024', '--num-attention-heads', '16', '--seq-length', '512', '--max-sequence-length', '513', '--save', '/dataset/fd5061f6/english_data/checkpoints', '--train-iters', '200000', '--resume-dataloader', '--train-data', 'wikipedia_ssm', '--tokenizer-type', 'GPT2BPETokenizer', '--tokenizer-model-type', 'gpt2', '--split', '949,50,1', '--distributed-backend', 'nccl', '--lr-decay-style', 'cosine', '--lr-decay-iters', '160000', '--lr-decay-ratio', '0.05', '--warmup', '.05', '--checkpoint-activations', '--fp16', '--deepspeed', '--deepspeed_config', '/dataset/fd5061f6/liuxiao/BlockLM-ssm/config/config_block_220M.json']' returned non-zero exit status 1.
pdsh@notebook8d8703c678-jupyter-master-0: 10.42.84.22: ssh exited with exit code 1
pdsh@notebook8d8703c678-jupyter-master-0: 10.42.9.12: ssh exited with exit code 1
pdsh@notebook8d8703c678-jupyter-master-0: 10.42.11.14: ssh exited with exit code 1
pdsh@notebook8d8703c678-jupyter-master-0: 10.42.93.14: ssh exited with exit code 1
